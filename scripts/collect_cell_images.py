"""
Cell Image Data Collector
Cell Image Library ë° ê³µê°œ ë°ì´í„°ì…‹ ìë™ ìˆ˜ì§‘
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from pathlib import Path
import json
import time
from datetime import datetime
from typing import List, Dict
import cv2
import numpy as np
from urllib.parse import urljoin


class CellImageCollector:
    """ê³µê°œ ì„¸í¬ ì´ë¯¸ì§€ ë°ì´í„° ìë™ ìˆ˜ì§‘"""
    
    def __init__(self, output_dir="data/collected_images"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë””ë ‰í† ë¦¬
        self.categories = {
            'antioxidant': self.output_dir / 'antioxidant',
            'anti_fibrotic': self.output_dir / 'anti_fibrotic',
            'anti_inflammatory': self.output_dir / 'anti_inflammatory',
            'angiogenic': self.output_dir / 'angiogenic',
            'proliferation': self.output_dir / 'proliferation',
            'unlabeled': self.output_dir / 'unlabeled'
        }
        
        for cat_dir in self.categories.values():
            cat_dir.mkdir(exist_ok=True)
        
        self.metadata = []
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def collect_from_kaggle_datasets(self):
        """Kaggle ê³µê°œ ì„¸í¬ ì´ë¯¸ì§€ ë°ì´í„°ì…‹"""
        
        print("\n" + "="*80)
        print("ğŸ“¦ Kaggle ë°ì´í„°ì…‹ ìˆ˜ì§‘")
        print("="*80 + "\n")
        
        # ì‹¤ì œë¡œëŠ” Kaggle API ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ê³µê°œ URL ì˜ˆì‹œ
        datasets = [
            {
                'name': 'Cell Image Classification',
                'url': 'https://www.kaggle.com/datasets/kmader/bioimage-classification',
                'category': 'general'
            }
        ]
        
        print("ğŸ’¡ Kaggle API ì„¤ì • í•„ìš”:")
        print("   1. https://www.kaggle.com/settings ì—ì„œ API Token ìƒì„±")
        print("   2. kaggle.jsonì„ ~/.kaggle/ ì— ì €ì¥")
        print("   3. pip install kaggle")
        print("\n   ì‹¤í–‰ ëª…ë ¹:")
        for ds in datasets:
            print(f"   kaggle datasets download -d {ds['name']}")
        
        return datasets
    
    def collect_from_sample_urls(self):
        """ìƒ˜í”Œ ê³µê°œ ì´ë¯¸ì§€ ìˆ˜ì§‘ (í…ŒìŠ¤íŠ¸ìš©)"""
        
        print("\n" + "="*80)
        print("ğŸ–¼ï¸  ìƒ˜í”Œ ì´ë¯¸ì§€ ìˆ˜ì§‘")
        print("="*80 + "\n")
        
        # ê³µê°œ ì„¸í¬ ì´ë¯¸ì§€ ìƒ˜í”Œ (ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” API ì‚¬ìš©)
        sample_sources = [
            "https://cellimages.example.com",  # ì˜ˆì‹œ
            "https://bioimage-archive.ebi.ac.uk"  # ì‹¤ì œ ì‚¬ì´íŠ¸
        ]
        
        print("ğŸ’¡ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ì„œëŠ”:")
        print("   - Cell Image Library API í‚¤ í•„ìš”")
        print("   - BioImage Archive ê³„ì • í•„ìš”")
        print("   - ë˜ëŠ” ì§ì ‘ ì œê³µí•˜ì‹  ì´ë¯¸ì§€ ì‚¬ìš©")
        
        return []
    
    def collect_from_existing_huvec(self):
        """ê¸°ì¡´ HUVEC ë°ì´í„° ìˆ˜ì§‘ ë° ì¡°ì§í™”"""
        
        print("\n" + "="*80)
        print("ğŸ“ ê¸°ì¡´ HUVEC ë°ì´í„° ì¡°ì§í™”")
        print("="*80 + "\n")
        
        huvec_dir = Path(r"c:\Users\brook\Desktop\mi_exo_ai\data\HUVEC TNF-a\HUVEC TNF-a\251209")
        
        if not huvec_dir.exists():
            print(f"âš ï¸  HUVEC ë°ì´í„° ì—†ìŒ: {huvec_dir}")
            return []
        
        images = list(huvec_dir.glob("*.jpg"))
        print(f"ğŸ“· ë°œê²¬ëœ ì´ë¯¸ì§€: {len(images)}ê°œ")
        
        collected = []
        for img_path in images:
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ ë° í’ˆì§ˆ ê²€ì‚¬
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                
                quality_ok, checks = self.check_image_quality(img)
                
                if quality_ok:
                    # unlabeled ì¹´í…Œê³ ë¦¬ë¡œ ë³µì‚¬
                    dest_path = self.categories['unlabeled'] / img_path.name
                    cv2.imwrite(str(dest_path), img)
                    
                    metadata = {
                        'source': 'HUVEC_TNF-a',
                        'original_path': str(img_path),
                        'new_path': str(dest_path),
                        'shape': img.shape,
                        'quality_checks': checks,
                        'category': 'unlabeled',
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    self.metadata.append(metadata)
                    collected.append(dest_path)
                    
                    print(f"  âœ“ {img_path.name}: {img.shape}")
                else:
                    print(f"  âœ— {img_path.name}: í’ˆì§ˆ ë¶ˆëŸ‰")
                    
            except Exception as e:
                print(f"  âœ— {img_path.name}: {e}")
        
        print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(collected)}ê°œ")
        return collected
    
    def check_image_quality(self, image: np.ndarray) -> tuple:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì‚¬"""
        
        checks = {}
        
        # 1. í•´ìƒë„
        h, w = image.shape[:2]
        checks['resolution_ok'] = h >= 256 and w >= 256
        
        # 2. ë°ê¸°
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        mean_brightness = gray.mean()
        checks['brightness_ok'] = 30 < mean_brightness < 225
        
        # 3. ëŒ€ë¹„
        std_brightness = gray.std()
        checks['contrast_ok'] = std_brightness > 20
        
        # 4. í¬ì»¤ìŠ¤ (Laplacian variance)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        checks['focus_ok'] = laplacian_var > 50
        
        # 5. ë…¸ì´ì¦ˆ ë ˆë²¨
        # ê°„ë‹¨í•œ ë…¸ì´ì¦ˆ ì¶”ì •
        noise_estimate = np.std(cv2.GaussianBlur(gray, (5, 5), 0) - gray)
        checks['noise_ok'] = noise_estimate < 30
        
        quality_ok = all(checks.values())
        return quality_ok, checks
    
    def generate_dataset_statistics(self):
        """ë°ì´í„°ì…‹ í†µê³„ ìƒì„±"""
        
        print("\n" + "="*80)
        print("ğŸ“Š ë°ì´í„°ì…‹ í†µê³„")
        print("="*80 + "\n")
        
        stats = {}
        total_images = 0
        
        for cat_name, cat_dir in self.categories.items():
            images = list(cat_dir.glob("*.jpg")) + list(cat_dir.glob("*.png"))
            count = len(images)
            total_images += count
            
            stats[cat_name] = {
                'count': count,
                'percentage': 0  # ë‚˜ì¤‘ì— ê³„ì‚°
            }
            
            print(f"{cat_name:20s}: {count:4d} images")
        
        # í¼ì„¼íŠ¸ ê³„ì‚°
        if total_images > 0:
            for cat in stats:
                stats[cat]['percentage'] = stats[cat]['count'] / total_images * 100
        
        print(f"\n{'TOTAL':20s}: {total_images:4d} images")
        
        return stats
    
    def save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        
        metadata_file = self.output_dir / 'metadata.json'
        
        summary = {
            'collection_date': datetime.now().isoformat(),
            'total_images': len(self.metadata),
            'categories': {
                cat: len([m for m in self.metadata if m['category'] == cat])
                for cat in self.categories.keys()
            },
            'images': self.metadata
        }
        
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_file}")
        
        return metadata_file
    
    def create_manifest(self):
        """í•™ìŠµìš© ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
        
        manifest_file = self.output_dir / 'train_manifest.csv'
        
        rows = []
        for meta in self.metadata:
            rows.append({
                'image_path': meta['new_path'],
                'category': meta['category'],
                'source': meta['source'],
                'quality_score': sum(meta['quality_checks'].values()) / len(meta['quality_checks'])
            })
        
        df = pd.DataFrame(rows)
        df.to_csv(manifest_file, index=False)
        
        print(f"ğŸ“ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±: {manifest_file}")
        print(f"   ì´ {len(df)}ê°œ ì´ë¯¸ì§€")
        
        return manifest_file


def main():
    """ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
    
    print("\n" + "="*80)
    print("ğŸš€ Cell Image Data Collection")
    print("ì‹ ì•½ ê°œë°œìš© AI í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘")
    print("="*80 + "\n")
    
    collector = CellImageCollector(output_dir="data/collected_images")
    
    # 1. ê¸°ì¡´ HUVEC ë°ì´í„° ìˆ˜ì§‘
    huvec_images = collector.collect_from_existing_huvec()
    
    # 2. Kaggle ë°ì´í„°ì…‹ ì•ˆë‚´
    kaggle_datasets = collector.collect_from_kaggle_datasets()
    
    # 3. í†µê³„
    stats = collector.generate_dataset_statistics()
    
    # 4. ë©”íƒ€ë°ì´í„° ì €ì¥
    if collector.metadata:
        collector.save_metadata()
        collector.create_manifest()
    
    print("\n" + "="*80)
    print("âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    print("="*80 + "\n")
    
    print("ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. Kaggle APIë¡œ ì¶”ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    print("   2. ìˆ˜ë™ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¼ë²¨ë§")
    print("   3. ë°ì´í„° ì¦ê°• (scripts/augment_dataset.py)")
    print("   4. ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    
    return collector


if __name__ == "__main__":
    collector = main()
