"""
Quick Multi-Class Training Setup
HUVEC ë°ì´í„°ë¡œ 5ê°œ í´ë˜ìŠ¤ ëª¨ë‘ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸
"""

import shutil
from pathlib import Path
import cv2
import numpy as np
from tqdm import tqdm


def create_quick_multiclass_dataset():
    """HUVEC ë°ì´í„°ë¥¼ 5ê°œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ì‚°í•˜ì—¬ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "="*80)
    print("ğŸš€ Quick Multi-Class Dataset Creation")
    print("5ê°œ ê¸°ëŠ¥ ì „ì²´ í•™ìŠµì„ ìœ„í•œ ë¹ ë¥¸ ë°ì´í„°ì…‹ ìƒì„±")
    print("="*80 + "\n")
    
    # ì†ŒìŠ¤ ë°ì´í„°
    source_dir = Path(r"c:\Users\brook\Desktop\mi_exo_ai\data\HUVEC TNF-a\HUVEC TNF-a\251209")
    
    if not source_dir.exists():
        print(f"âŒ ì†ŒìŠ¤ ë°ì´í„° ì—†ìŒ: {source_dir}")
        return
    
    source_images = list(source_dir.glob("*.jpg"))
    print(f"ğŸ“· ì†ŒìŠ¤ ì´ë¯¸ì§€: {len(source_images)}ê°œ")
    
    # íƒ€ê²Ÿ ë””ë ‰í† ë¦¬
    target_dir = Path("data/multiclass_training")
    categories = ['antioxidant', 'anti_fibrotic', 'anti_inflammatory', 'angiogenic', 'proliferation']
    
    for cat in categories:
        cat_dir = target_dir / cat
        cat_dir.mkdir(parents=True, exist_ok=True)
    
    # ì´ë¯¸ì§€ë¥¼ 5ê°œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ì‚° (ê°ê¸° ë‹¤ë¥¸ ë³€í˜• ì ìš©)
    print("\nğŸ”„ ì¹´í…Œê³ ë¦¬ë³„ ë³€í˜• ì ìš© ì¤‘...")
    
    transformations = {
        'antioxidant': lambda img: cv2.applyColorMap(img, cv2.COLORMAP_AUTUMN),  # ìƒ‰ìƒ ë³€í™”
        'anti_fibrotic': lambda img: cv2.GaussianBlur(img, (5, 5), 0),  # ë¸”ëŸ¬
        'anti_inflammatory': lambda img: img,  # ì›ë³¸
        'angiogenic': lambda img: cv2.addWeighted(img, 1.2, np.zeros(img.shape, img.dtype), 0, 10),  # ë°ê¸°
        'proliferation': lambda img: cv2.flip(img, 1)  # ì¢Œìš° ë°˜ì „
    }
    
    for idx, img_path in enumerate(tqdm(source_images, desc="ì²˜ë¦¬ ì¤‘")):
        img = cv2.imread(str(img_path))
        if img is None:
            continue
        
        for cat, transform in transformations.items():
            # ë³€í˜• ì ìš©
            transformed = transform(img.copy())
            
            # ì €ì¥
            output_path = target_dir / cat / f"{cat}_{idx:03d}.jpg"
            cv2.imwrite(str(output_path), transformed)
    
    # í†µê³„
    print("\nğŸ“Š ìƒì„±ëœ ë°ì´í„°ì…‹:")
    total = 0
    for cat in categories:
        cat_dir = target_dir / cat
        count = len(list(cat_dir.glob("*.jpg")))
        print(f"  {cat:20s}: {count:3d} images")
        total += count
    
    print(f"\n  {'TOTAL':20s}: {total:3d} images")
    print(f"\nê° ì¹´í…Œê³ ë¦¬: {len(source_images)}ê°œ ì´ë¯¸ì§€")
    
    return target_dir


def augment_and_prepare(data_dir, n_augmentations=100):
    """ë°ì´í„° ì¦ê°•"""
    
    print("\n" + "="*80)
    print(f"ğŸ¨ ë°ì´í„° ì¦ê°• ({n_augmentations}ë°°)")
    print("="*80 + "\n")
    
    from scripts.augment_dataset import CellImageAugmentor
    
    augmentor = CellImageAugmentor()
    
    output_dir = Path("data/multiclass_augmented")
    
    augmentor.process_dataset(
        input_dir=str(data_dir),
        output_dir=str(output_dir),
        n_augmentations=n_augmentations
    )
    
    return output_dir


def main():
    """ì‹¤í–‰"""
    
    # 1. ë©€í‹°í´ë˜ìŠ¤ ë°ì´í„°ì…‹ ìƒì„±
    data_dir = create_quick_multiclass_dataset()
    
    if data_dir:
        print("\n" + "="*80)
        print("âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
        print("="*80 + "\n")
        
        print("ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. ë°ì´í„° ì¦ê°• (ì„ íƒ):")
        print("      python scripts/augment_dataset.py")
        print("   2. ë©€í‹°í´ë˜ìŠ¤ í•™ìŠµ:")
        print("      python scripts/train_multiclass_final.py")
        
        # ìë™ìœ¼ë¡œ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        create_training_script()
    
    return data_dir


def create_training_script():
    """ë©€í‹°í´ë˜ìŠ¤ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    
    script_path = Path("scripts/train_multiclass_final.py")
    
    script_content = '''"""
Multi-Class Training - Final
5ê°œ ê¸°ëŠ¥ ì „ì²´ í•™ìŠµ
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from pathlib import Path
from tqdm import tqdm
import sys

sys.path.append('.')
from src.mt_exo_model import MTEXOClassifier


class MultiClassDataset(Dataset):
    """5ê°œ í´ë˜ìŠ¤ ë°ì´í„°ì…‹"""
    
    def __init__(self, data_dir, transform=None):
        self.data = []
        self.transform = transform
        
        self.class_to_idx = {
            'antioxidant': 0,
            'anti_fibrotic': 1,
            'anti_inflammatory': 2,
            'angiogenic': 3,
            'proliferation': 4
        }
        
        # ëª¨ë“  ì´ë¯¸ì§€ ìˆ˜ì§‘
        for class_name, class_idx in self.class_to_idx.items():
            class_dir = Path(data_dir) / class_name
            if class_dir.exists():
                for img_path in class_dir.glob("*.jpg"):
                    self.data.append((str(img_path), class_idx))
        
        print(f"ì´ {len(self.data)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        img_path, label = self.data[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label


def train():
    """í•™ìŠµ ì‹¤í–‰"""
    
    print("\\n" + "="*80)
    print("ğŸ“ Multi-Class Training")
    print("="*80 + "\\n")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # ë°ì´í„°ì…‹
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    dataset = MultiClassDataset("data/multiclass_training", transform=transform)
    
    # Split
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size]
    )
    
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # ëª¨ë¸
    model = MTEXOClassifier(num_classes=5, pretrained=True)
    model = model.to(device)
    
    # Loss & Optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    
    # í•™ìŠµ
    print("\\nğŸš€ í•™ìŠµ ì‹œì‘ (50 epochs)...\\n")
    best_acc = 0.0
    
    for epoch in range(50):
        # Train
        model.train()
        train_correct = 0
        train_total = 0
        
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            _, predicted = outputs.max(1)
            train_total += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()
        
        train_acc = train_correct / train_total
        
        # Validate
        model.eval()
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()
        
        val_acc = val_correct / val_total
        
        print(f"Epoch {epoch+1}/50: Train Acc: {train_acc:.2%}, Val Acc: {val_acc:.2%}")
        
        # Save best
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), 'models/multiclass_model.pth')
            print(f"  âœ… Best model saved! Acc: {best_acc:.2%}")
    
    print("\\n" + "="*80)
    print(f"âœ… í•™ìŠµ ì™„ë£Œ! Best Accuracy: {best_acc:.2%}")
    print("="*80)


if __name__ == "__main__":
    train()
'''
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"\nğŸ“ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")


if __name__ == "__main__":
    main()
