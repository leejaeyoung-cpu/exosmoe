"""
Quick Training with HUVEC Data
HUVEC ë°ì´í„°ë¡œ ë¹ ë¥¸ í•™ìŠµ ì‹œìž‘
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
from pathlib import Path
from tqdm import tqdm
import cv2

import sys
sys.path.append('.')

from src.mt_exo_model import MTEXOClassifier


class HUVECDataset(Dataset):
    """HUVEC ë°ì´í„°ì…‹ (ê°„ë‹¨ ë²„ì „)"""
    
    def __init__(self, image_dir, transform=None):
        self.image_paths = list(Path(image_dir).glob("*.jpg"))
        self.transform = transform
        
        # ìž„ì‹œ ë¼ë²¨: ëª¨ë‘ 'í•­ì—¼ì¦'ìœ¼ë¡œ (TNF-Î± ì²˜ë¦¬ì´ë¯€ë¡œ)
        self.label = 2  # anti_inflammatory
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, self.label


class SimpleAugmentation:
    """ê°„ë‹¨í•œ ì¦ê°•"""
    
    @staticmethod
    def augment_image(image_path, n=100):
        """ì´ë¯¸ì§€ 1ê°œë¥¼ nê°œë¡œ ì¦ê°•"""
        
        img = cv2.imread(str(image_path))
        augmented = [img]  # ì›ë³¸ í¬í•¨
        
        for i in range(n-1):
            # ëžœë¤ ë³€í™˜
            aug = img.copy()
            
            # íšŒì „
            angle = np.random.uniform(-180, 180)
            h, w = aug.shape[:2]
            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
            aug = cv2.warpAffine(aug, M, (w, h))
            
            # í”Œë¦½
            if np.random.rand() > 0.5:
                aug = cv2.flip(aug, 1)
            if np.random.rand() > 0.5:
                aug = cv2.flip(aug, 0)
            
            # ë°ê¸°
            factor = np.random.uniform(0.7, 1.3)
            aug = np.clip(aug * factor, 0, 255).astype(np.uint8)
            
            augmented.append(aug)
        
        return augmented


def quick_train():
    """ë¹ ë¥¸ í•™ìŠµ ì‹œìž‘"""
    
    print("\n" + "="*80)
    print("ðŸš€ Quick Training with HUVEC Data")
    print("="*80 + "\n")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # HUVEC ë°ì´í„° ê²½ë¡œ
    huvec_dir = Path(r"c:\Users\brook\Desktop\mi_exo_ai\data\HUVEC TNF-a\HUVEC TNF-a\251209")
    
    if not huvec_dir.exists():
        print(f"âŒ HUVEC ë°ì´í„° ì—†ìŒ: {huvec_dir}")
        return
    
    images = list(huvec_dir.glob("*.jpg"))
    print(f"ðŸ“· ì›ë³¸ ì´ë¯¸ì§€: {len(images)}ê°œ")
    
    # ì¦ê°•
    print("\nðŸ”„ ë°ì´í„° ì¦ê°• ì¤‘...")
    augmented_dir = Path("data/quick_train")
    augmented_dir.mkdir(exist_ok=True, parents=True)
    
    augmentor = SimpleAugmentation()
    total_augmented = 0
    
    for img_path in tqdm(images, desc="ì¦ê°•"):
        augmented = augmentor.augment_image(img_path, n=100)
        
        for i, aug_img in enumerate(augmented):
            save_path = augmented_dir / f"{img_path.stem}_aug{i:04d}.jpg"
            cv2.imwrite(str(save_path), aug_img)
            total_augmented += 1
    
    print(f"âœ… ì´ {total_augmented}ê°œ ì´ë¯¸ì§€ ìƒì„±")
    
    # ë°ì´í„°ì…‹
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    dataset = HUVECDataset(augmented_dir, transform=transform)
    
    # Train/Val split
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size]
    )
    
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    print(f"\nðŸ“Š ë°ì´í„°: Train {train_size}, Val {val_size}")
    
    # ëª¨ë¸
    print("\nðŸ¤– ëª¨ë¸ ë¡œë”©...")
    model = MTEXOClassifier(num_classes=5, pretrained=True)
    model = model.to(device)
    
    # Loss & Optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    
    # í•™ìŠµ
    print("\nðŸŽ“ í•™ìŠµ ì‹œìž‘ (50 epochs)...")
    best_acc = 0.0
    
    for epoch in range(50):
        # Train
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()
        
        train_acc = train_correct / train_total
        
        # Validate
        model.eval()
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()
        
        val_acc = val_correct / val_total
        
        print(f"Epoch {epoch+1}/50: Train Acc: {train_acc:.2%}, Val Acc: {val_acc:.2%}")
        
        # Save best
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), 'models/quick_trained_model.pth')
            print(f"  âœ… Best model saved! Acc: {best_acc:.2%}")
    
    print("\n" + "="*80)
    print(f"âœ… í•™ìŠµ ì™„ë£Œ! Best Accuracy: {best_acc:.2%}")
    print("="*80)
    
    return model


if __name__ == "__main__":
    model = quick_train()
