"""
AI-Driven Drug Discovery Pipeline for CKD-CVD
Phase 1: Literature Mining and Knowledge Extraction

ì´ ëª¨ë“ˆì€ PubMedì—ì„œ ìë™ìœ¼ë¡œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import requests
import json
import pandas as pd
from pathlib import Path
from typing import List, Dict
import time
from xml.etree import ElementTree as ET

class LiteratureMiner:
    """
    PubMed APIë¥¼ ì‚¬ìš©í•œ ë¬¸í—Œ ë§ˆì´ë‹
    """
    
    def __init__(self, email="research@example.com"):
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
        self.email = email
        self.output_dir = Path("data/literature")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def search_papers(self, query: str, max_results: int = 100) -> List[str]:
        """
        PubMedì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ì–´
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            PubMed ID ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ” ê²€ìƒ‰ ì¤‘: '{query}'...")
        
        search_url = f"{self.base_url}esearch.fcgi"
        params = {
            'db': 'pubmed',
            'term': query,
            'retmax': max_results,
            'retmode': 'json',
            'email': self.email,
            # ìµœê·¼ 5ë…„ ë…¼ë¬¸ë§Œ
            'reldate': 1825,  # 5 years in days
            'datetype': 'pdat'
        }
        
        try:
            response = requests.get(search_url, params=params)
            response.raise_for_status()
            data = response.json()
            
            pmids = data.get('esearchresult', {}).get('idlist', [])
            print(f"   âœ… {len(pmids)}ê°œ ë…¼ë¬¸ ë°œê²¬")
            return pmids
            
        except Exception as e:
            print(f"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def fetch_abstracts(self, pmids: List[str]) -> List[Dict]:
        """
        PubMed IDë¡œ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            pmids: PubMed ID ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ì œëª©, ì´ˆë¡, ì €ì, ì €ë„ ë“±)
        """
        print(f"ğŸ“¥ {len(pmids)}ê°œ ë…¼ë¬¸ ì´ˆë¡ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        fetch_url = f"{self.base_url}efetch.fcgi"
        papers = []
        
        # API rate limitì„ ìœ„í•´ ë°°ì¹˜ ì²˜ë¦¬
        batch_size = 50
        for i in range(0, len(pmids), batch_size):
            batch = pmids[i:i+batch_size]
            params = {
                'db': 'pubmed',
                'id': ','.join(batch),
                'retmode': 'xml',
                'email': self.email
            }
            
            try:
                response = requests.get(fetch_url, params=params)
                response.raise_for_status()
                
                # XML íŒŒì‹±
                root = ET.fromstring(response.content)
                
                for article in root.findall('.//PubmedArticle'):
                    try:
                        # PMID
                        pmid = article.find('.//PMID').text
                        
                        # ì œëª©
                        title_elem = article.find('.//ArticleTitle')
                        title = title_elem.text if title_elem is not None else "No title"
                        
                        # ì´ˆë¡
                        abstract_elem = article.find('.//AbstractText')
                        abstract = abstract_elem.text if abstract_elem is not None else "No abstract available"
                        
                        # ì €ë„
                        journal_elem = article.find('.//Journal/Title')
                        journal = journal_elem.text if journal_elem is not None else "Unknown"
                        
                        # ë…„ë„
                        year_elem = article.find('.//PubDate/Year')
                        year = year_elem.text if year_elem is not None else "Unknown"
                        
                        papers.append({
                            'pmid': pmid,
                            'title': title,
                            'abstract': abstract,
                            'journal': journal,
                            'year': year
                        })
                        
                    except Exception as e:
                        print(f"   âš ï¸ ë…¼ë¬¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # API rate limit ì¤€ìˆ˜
                time.sleep(0.5)
                print(f"   ì§„í–‰: {min(i+batch_size, len(pmids))}/{len(pmids)}")
                
            except Exception as e:
                print(f"   âŒ ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"   âœ… ì´ {len(papers)}ê°œ ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        return papers
    
    def mine_ckd_cvd_literature(self, papers_per_query: int = 20) -> pd.DataFrame:
        """
        CKD-CVD ê´€ë ¨ ë¬¸í—Œ ì¢…í•© ìˆ˜ì§‘
        
        Returns:
            ë…¼ë¬¸ ì •ë³´ DataFrame
        """
        print("\n" + "="*70)
        print("CKD-CVD ë¬¸í—Œ ë§ˆì´ë‹ ì‹œì‘")
        print("="*70)
        
        queries = [
            "chronic kidney disease drug discovery",
            "cardiovascular disease therapeutic targets",
            "NF-kappa B inhibitor kidney",
            "TGF-beta antagonist renal fibrosis",
            "mitochondrial protection chronic kidney disease",
            "endothelial dysfunction cardiovascular disease treatment",
            "oxidative stress kidney disease therapy",
            "inflammation kidney cardiovascular disease",
        ]
        
        all_papers = []
        all_pmids = set()
        
        for query in queries:
            pmids = self.search_papers(query, max_results=papers_per_query)
            
            # ì¤‘ë³µ ì œê±°
            new_pmids = [pmid for pmid in pmids if pmid not in all_pmids]
            if new_pmids:
                papers = self.fetch_abstracts(new_pmids)
                all_papers.extend(papers)
                all_pmids.update(new_pmids)
            
            time.sleep(1)  # API rate limit
        
        df = pd.DataFrame(all_papers)
        
        # ì €ì¥
        output_file = self.output_dir / "ckd_cvd_literature.csv"
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ì €ì¥: {output_file}")
        print(f"ğŸ“Š ì´ {len(df)}ê°œ ê³ ìœ  ë…¼ë¬¸ ìˆ˜ì§‘")
        
        return df


class KnowledgeExtractor:
    """
    ë…¼ë¬¸ì—ì„œ í•µì‹¬ ì§€ì‹ ì¶”ì¶œ
    (ê°„ì†Œí™” ë²„ì „ - í‚¤ì›Œë“œ ê¸°ë°˜)
    """
    
    def __init__(self):
        # CKD-CVD ê´€ë ¨ í•µì‹¬ íƒ€ê²Ÿ
        self.targets = {
            'NF-ÎºB': ['NF-kappa B', 'NF-kappaB', 'NFKB', 'p65', 'RelA'],
            'TGF-Î²': ['TGF-beta', 'TGF-Î²', 'TGFB', 'transforming growth factor'],
            'NOX4': ['NADPH oxidase 4', 'NOX4'],
            'VCAM1': ['VCAM-1', 'VCAM1', 'vascular cell adhesion'],
            'ICAM1': ['ICAM-1', 'ICAM1', 'intercellular adhesion'],
            'mTOR': ['mTOR', 'mammalian target of rapamycin'],
            'AMPK': ['AMPK', 'AMP-activated protein kinase'],
            'Nrf2': ['Nrf2', 'NRF2', 'nuclear factor erythroid'],
        }
        
        # ì¹˜ë£Œ ë©”ì»¤ë‹ˆì¦˜
        self.mechanisms = {
            'inhibitor': ['inhibit', 'suppress', 'block', 'antagonist'],
            'activator': ['activate', 'enhance', 'agonist', 'induce'],
            'modulator': ['modulate', 'regulate', 'control'],
        }
    
    def extract_targets(self, papers_df: pd.DataFrame) -> pd.DataFrame:
        """
        ë…¼ë¬¸ì—ì„œ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ ì–¸ê¸‰ ì¶”ì¶œ
        
        Returns:
            íƒ€ê²Ÿë³„ ì–¸ê¸‰ ë¹ˆë„ ë° ê´€ë ¨ ë…¼ë¬¸
        """
        print("\n" + "="*70)
        print("íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ ì¶”ì¶œ")
        print("="*70)
        
        target_mentions = []
        
        for idx, row in papers_df.iterrows():
            text = f"{row['title']} {row['abstract']}".lower()
            
            for target, keywords in self.targets.items():
                for keyword in keywords:
                    if keyword.lower() in text:
                        target_mentions.append({
                            'pmid': row['pmid'],
                            'target': target,
                            'keyword': keyword,
                            'title': row['title'],
                            'year': row['year']
                        })
                        break  # í•˜ë‚˜ë§Œ ì°¾ìœ¼ë©´ ë¨
        
        df_targets = pd.DataFrame(target_mentions)
        
        # íƒ€ê²Ÿë³„ í†µê³„
        if not df_targets.empty:
            target_stats = df_targets['target'].value_counts()
            print(f"\nğŸ“Š íƒ€ê²Ÿ ì–¸ê¸‰ ë¹ˆë„:")
            for target, count in target_stats.items():
                print(f"   {target}: {count}íšŒ")
        
        return df_targets
    
    def extract_molecules(self, papers_df: pd.DataFrame) -> List[Dict]:
        """
        ë…¼ë¬¸ì—ì„œ ì ì¬ì  ì¹˜ë£Œ ë¶„ì ì¶”ì¶œ
        (ê¸°ì¡´ ì•½ë¬¼ ë° í™”í•©ë¬¼)
        
        Returns:
            ë¶„ì ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        print("\n" + "="*70)
        print("ì¹˜ë£Œ ë¶„ì ì¶”ì¶œ")
        print("="*70)
        
        # ì•Œë ¤ì§„ ì•½ë¬¼/í™”í•©ë¬¼ í‚¤ì›Œë“œ
        known_molecules = {
            'Metformin': ['diabetes', 'AMPK'],
            'Bardoxolone': ['Nrf2', 'oxidative stress'],
            'Pirfenidone': ['fibrosis', 'TGF-beta'],
            'Losartan': ['angiotensin', 'fibrosis'],
            'Curcumin': ['NF-kappa B', 'inflammation'],
            'Resveratrol': ['oxidative', 'mitochondria'],
            'N-acetylcysteine': ['antioxidant', 'glutathione'],
        }
        
        molecules = []
        
        for molecule, contexts in known_molecules.items():
            count = 0
            pmids = []
            
            for idx, row in papers_df.iterrows():
                text = f"{row['title']} {row['abstract']}".lower()
                
                if molecule.lower() in text:
                    # Context í™•ì¸
                    relevant = any(ctx.lower() in text for ctx in contexts)
                    if relevant:
                        count += 1
                        pmids.append(row['pmid'])
            
            if count > 0:
                molecules.append({
                    'molecule': molecule,
                    'mentions': count,
                    'pmids': pmids[:5],  # ìƒìœ„ 5ê°œë§Œ
                    'context': ', '.join(contexts)
                })
        
        # ì •ë ¬
        molecules = sorted(molecules, key=lambda x: x['mentions'], reverse=True)
        
        print(f"\nğŸ’Š ë°œê²¬ëœ ì¹˜ë£Œ ë¶„ì ({len(molecules)}ê°œ):")
        for mol in molecules[:10]:
            print(f"   {mol['molecule']}: {mol['mentions']}íšŒ ì–¸ê¸‰")
        
        return molecules


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("\n" + "="*70)
    print("AI ê¸°ë°˜ CKD-CVD ì‹ ì•½ ë°œê²¬ íŒŒì´í”„ë¼ì¸")
    print("Phase 1: ë¬¸í—Œ ë§ˆì´ë‹ ë° ì§€ì‹ ì¶”ì¶œ")
    print("="*70)
    
    # Step 1: ë¬¸í—Œ ìˆ˜ì§‘
    miner = LiteratureMiner()
    papers_df = miner.mine_ckd_cvd_literature(papers_per_query=15)
    
    # Step 2: ì§€ì‹ ì¶”ì¶œ
    extractor = KnowledgeExtractor()
    
    # íƒ€ê²Ÿ ì¶”ì¶œ
    targets_df = extractor.extract_targets(papers_df)
    targets_df.to_csv("data/literature/extracted_targets.csv", index=False, encoding='utf-8-sig')
    
    # ë¶„ì ì¶”ì¶œ
    molecules = extractor.extract_molecules(papers_df)
    pd.DataFrame(molecules).to_csv("data/literature/extracted_molecules.csv", index=False, encoding='utf-8-sig')
    
    print("\n" + "="*70)
    print("âœ… Phase 1 ì™„ë£Œ!")
    print(f"   ğŸ“„ ì´ ë…¼ë¬¸: {len(papers_df)}ê°œ")
    print(f"   ğŸ¯ íƒ€ê²Ÿ: {len(targets_df)}ê°œ ì–¸ê¸‰")
    print(f"   ğŸ’Š ë¶„ì: {len(molecules)}ê°œ ë°œê²¬")
    print("="*70)
    
    return papers_df, targets_df, molecules


if __name__ == "__main__":
    papers, targets, molecules = main()
