"""
Advanced MT-EXO Deep Learning Model
ResNet50 + Attention + Explainable AI
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
from typing import Tuple, Dict, Optional
import numpy as np


class SpatialAttention(nn.Module):
    """ê³µê°„ì  ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ (ì¤‘ìš” ì˜ì—­ ê°•ì¡°)"""
    
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        # ì±„ë„ ì°¨ì›ì—ì„œ í‰ê· ê³¼ ìµœëŒ€ê°’
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        
        # Concatenate
        x_cat = torch.cat([avg_out, max_out], dim=1)
        
        # Attention map ìƒì„±
        attention = self.sigmoid(self.conv(x_cat))
        
        return x * attention


class ChannelAttention(nn.Module):
    """ì±„ë„ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ (ì¤‘ìš” íŠ¹ì§• ê°•ì¡°)"""
    
    def __init__(self, in_channels, reduction_ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        b, c, _, _ = x.size()
        
        # Average pooling
        avg_out = self.fc(self.avg_pool(x).view(b, c))
        
        # Max pooling
        max_out = self.fc(self.max_pool(x).view(b, c))
        
        # Attention
        attention = self.sigmoid(avg_out + max_out).view(b, c, 1, 1)
        
        return x * attention


class MTEXOClassifier(nn.Module):
    """
    MT-EXO ê¸°ëŠ¥ ë¶„ë¥˜ ëª¨ë¸
    
    Architecture:
    - Backbone: ResNet50 (ImageNet pretrained)
    - Attention: Spatial + Channel Attention
    - Classifier: 5ê°œ ê¸°ëŠ¥ ë¶„ë¥˜
    """
    
    def __init__(self, num_classes=5, pretrained=True, dropout=0.5):
        super(MTEXOClassifier, self).__init__()
        
        # ResNet50 ë°±ë³¸
        resnet = models.resnet50(pretrained=pretrained)
        
        # ë°±ë³¸ ë ˆì´ì–´ ì¶”ì¶œ (FC ì œì™¸)
        self.conv1 = resnet.conv1
        self.bn1 = resnet.bn1
        self.relu = resnet.relu
        self.maxpool = resnet.maxpool
        
        self.layer1 = resnet.layer1
        self.layer2 = resnet.layer2
        self.layer3 = resnet.layer3
        self.layer4 = resnet.layer4
        
        # Attention ëª¨ë“ˆ
        self.channel_attention = ChannelAttention(2048)
        self.spatial_attention = SpatialAttention()
        
        # Global Average Pooling
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        
        # Classifier Head
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(2048, num_classes)
        
        # í´ë˜ìŠ¤ ì´ë¦„
        self.class_names = [
            'í•­ì‚°í™”',
            'í•­ì„¬ìœ í™”', 
            'í•­ì—¼ì¦',
            'í˜ˆê´€í˜•ì„±',
            'ì„¸í¬ì¦ì‹'
        ]
    
    def forward(self, x):
        # ë°±ë³¸ í†µê³¼
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        
        # Attention ì ìš©
        x = self.channel_attention(x)
        x = self.spatial_attention(x)
        
        # Pooling & Flatten
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        
        # Dropout & Classification
        x = self.dropout(x)
        x = self.fc(x)
        
        return x
    
    def predict_with_confidence(self, x):
        """ì˜ˆì¸¡ + ì‹ ë¢°ë„ ì ìˆ˜"""
        self.eval()
        with torch.no_grad():
            logits = self.forward(x)
            probabilities = F.softmax(logits, dim=1)
            
            confidence, predicted = torch.max(probabilities, dim=1)
            
        return predicted, confidence, probabilities


class ExplainableAI:
    """ì„¤ëª… ê°€ëŠ¥í•œ AI (Grad-CAM)"""
    
    def __init__(self, model: MTEXOClassifier):
        self.model = model
        self.gradients = None
        self.activations = None
        
        # Hook ë“±ë¡
        self.model.layer4.register_forward_hook(self.save_activation)
        self.model.layer4.register_backward_hook(self.save_gradient)
    
    def save_activation(self, module, input, output):
        """Forward hook: activation ì €ì¥"""
        self.activations = output.detach()
    
    def save_gradient(self, module, grad_input, grad_output):
        """Backward hook: gradient ì €ì¥"""
        self.gradients = grad_output[0].detach()
    
    def generate_heatmap(self, input_tensor, target_class=None):
        """
        Grad-CAM íˆíŠ¸ë§µ ìƒì„±
        
        Args:
            input_tensor: ì…ë ¥ ì´ë¯¸ì§€ (1, 3, H, W)
            target_class: Noneì´ë©´ ì˜ˆì¸¡ í´ë˜ìŠ¤, ì§€ì •í•˜ë©´ í•´ë‹¹ í´ë˜ìŠ¤
            
        Returns:
            heatmap: numpy array (H, W)
        """
        self.model.eval()
        
        # Forward pass
        output = self.model(input_tensor)
        
        if target_class is None:
            target_class = output.argmax(dim=1)
        
        # Backward pass
        self.model.zero_grad()
        class_loss = output[0, target_class]
        class_loss.backward()
        
        # Grad-CAM ê³„ì‚°
        pooled_gradients = torch.mean(self.gradients, dim=[0, 2, 3])
        
        for i in range(self.activations.shape[1]):
            self.activations[:, i, :, :] *= pooled_gradients[i]
        
        # íˆíŠ¸ë§µ
        heatmap = torch.mean(self.activations, dim=1).squeeze()
        heatmap = F.relu(heatmap)  # ReLU
        heatmap /= torch.max(heatmap)  # Normalize
        
        return heatmap.cpu().numpy()
    
    def overlay_heatmap(self, image, heatmap, alpha=0.4):
        """
        ì›ë³¸ ì´ë¯¸ì§€ì— íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€ (H, W, 3) numpy array
            heatmap: Grad-CAM íˆíŠ¸ë§µ (H, W)
            alpha: íˆ¬ëª…ë„
            
        Returns:
            overlayed image
        """
        import cv2
        
        # íˆíŠ¸ë§µ ë¦¬ì‚¬ì´ì¦ˆ
        heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))
        
        # ì»¬ëŸ¬ë§µ ì ìš©
        heatmap_colored = cv2.applyColorMap(
            np.uint8(255 * heatmap_resized), 
            cv2.COLORMAP_JET
        )
        
        # ì˜¤ë²„ë ˆì´
        overlay = cv2.addWeighted(image, 1-alpha, heatmap_colored, alpha, 0)
        
        return overlay


def create_model(pretrained=True, num_classes=5):
    """ëª¨ë¸ ìƒì„± í—¬í¼ í•¨ìˆ˜"""
    model = MTEXOClassifier(
        num_classes=num_classes,
        pretrained=pretrained,
        dropout=0.5
    )
    return model


def test_model():
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("ğŸ¤– MT-EXO Deep Learning Model í…ŒìŠ¤íŠ¸")
    print("="*80 + "\n")
    
    # ëª¨ë¸ ìƒì„±
    print("ëª¨ë¸ ìƒì„± ì¤‘...")
    model = create_model(pretrained=True, num_classes=5)
    
    # ëª¨ë¸ ì •ë³´
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"âœ“ ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
    print(f"âœ“ í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}")
    print(f"âœ“ í´ë˜ìŠ¤ ìˆ˜: 5 ({', '.join(model.class_names)})")
    
    # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    print("\nìˆœì „íŒŒ í…ŒìŠ¤íŠ¸ ì¤‘...")
    dummy_input = torch.randn(1, 3, 224, 224)  # Batch=1, RGB, 224x224
    
    model.eval()
    with torch.no_grad():
        output = model(dummy_input)
        predicted, confidence, probabilities = model.predict_with_confidence(dummy_input)
    
    print(f"âœ“ ì¶œë ¥ shape: {output.shape}")
    print(f"âœ“ ì˜ˆì¸¡ í´ë˜ìŠ¤: {model.class_names[predicted.item()]}")
    print(f"âœ“ ì‹ ë¢°ë„: {confidence.item():.3f}")
    
    print("\ní´ë˜ìŠ¤ë³„ í™•ë¥ :")
    for i, (name, prob) in enumerate(zip(model.class_names, probabilities[0])):
        print(f"  {i+1}. {name:12s}: {prob.item():.3f}")
    
    # Explainable AI í…ŒìŠ¤íŠ¸
    print("\nGrad-CAM í…ŒìŠ¤íŠ¸ ì¤‘...")
    xai = ExplainableAI(model)
    
    dummy_input.requires_grad = True
    heatmap = xai.generate_heatmap(dummy_input)
    
    print(f"âœ“ íˆíŠ¸ë§µ shape: {heatmap.shape}")
    print(f"âœ“ íˆíŠ¸ë§µ ë²”ìœ„: [{heatmap.min():.3f}, {heatmap.max():.3f}]")
    
    print("\n" + "="*80)
    print("âœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80 + "\n")


if __name__ == "__main__":
    test_model()
