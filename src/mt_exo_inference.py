"""
MT-EXO AI Inference Engine
Cellpose + Deep Learning í†µí•© ì¶”ë¡  ì‹œìŠ¤í…œ
"""

import torch
import torch.nn.functional as F
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import json
from datetime import datetime
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.advanced_cellpose_processor import AdvancedCellposeProcessor
from src.mt_exo_model import MTEXOClassifier, ExplainableAI


class MTEXOInferenceEngine:
    """
    MT-EXO í†µí•© ì¶”ë¡  ì—”ì§„
    
    Pipeline:
    1. ì´ë¯¸ì§€ ì…ë ¥
    2. Cellpose ì„¸ê·¸ë©˜í…Œì´ì…˜
    3. íŠ¹ì§• ì¶”ì¶œ
    4. ë”¥ëŸ¬ë‹ ì¶”ë¡ 
    5. Grad-CAM ì„¤ëª…
    """
    
    def __init__(self, model_path: Optional[str] = None, use_gpu: bool = True):
        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')
        print(f"ğŸ”§ Inference Engine ì´ˆê¸°í™”: Device={self.device}")
        
        # Cellpose í”„ë¡œì„¸ì„œ
        self.cellpose = AdvancedCellposeProcessor(model_type='cyto2', use_gpu=use_gpu)
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸
        self.model = MTEXOClassifier(num_classes=5, pretrained=True)
        
        # í•™ìŠµëœ ëª¨ë¸ ìë™ ë¡œë“œ (ìš°ì„ ìˆœìœ„: multiclass > quick_trained)
        multiclass_model_path = Path("models/multiclass_model.pth")
        quick_model_path = Path("models/quick_trained_model.pth")
        
        if model_path and Path(model_path).exists():
            print(f"âœ“ ëª¨ë¸ ë¡œë“œ: {model_path}")
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        elif multiclass_model_path.exists():
            print(f"âœ“ ë©€í‹°í´ë˜ìŠ¤ ëª¨ë¸ ë¡œë“œ: {multiclass_model_path}")
            self.model.load_state_dict(torch.load(multiclass_model_path, map_location=self.device))
            print("  ğŸ¯ 5ê°œ ê¸°ëŠ¥ ì „ì²´ ë¶„ë¥˜ ê°€ëŠ¥!")
        elif quick_model_path.exists():
            print(f"âœ“ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ: {quick_model_path}")
            self.model.load_state_dict(torch.load(quick_model_path, map_location=self.device))
            print("  ğŸ¯ ì‹ ë¢°ë„ í–¥ìƒ ëª¨ë¸ ì ìš©!")
        else:
            print("âš ï¸  ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì—†ìŒ - ImageNet ê°€ì¤‘ì¹˜ ì‚¬ìš©")
        
        self.model.to(self.device)
        self.model.eval()
        
        # Explainable AI
        self.xai = ExplainableAI(self.model)
        
        # í´ë˜ìŠ¤ ì´ë¦„
        self.class_names = self.model.class_names
    
    def preprocess_image(self, image: np.ndarray) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë”¥ëŸ¬ë‹ ì…ë ¥ìš©)
        
        Args:
            image: BGR image (H, W, 3)
            
        Returns:
            tensor: (1, 3, 224, 224)
        """
        # BGR â†’ RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        image_resized = cv2.resize(image_rgb, (224, 224))
        
        # ì •ê·œí™” (ImageNet í‰ê· /í‘œì¤€í¸ì°¨)
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        
        image_normalized = (image_resized / 255.0 - mean) / std
        
        # Transpose: (H, W, C) â†’ (C, H, W)
        image_transposed = np.transpose(image_normalized, (2, 0, 1))
        
        # To tensor: (1, C, H, W)
        tensor = torch.FloatTensor(image_transposed).unsqueeze(0)
        
        return tensor
    
    def predict(self, image_path: str, explain: bool = True) -> Dict:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
        
        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            explain: Grad-CAM ìƒì„± ì—¬ë¶€
            
        Returns:
            ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
        
        # Cellpose ì„¸ê·¸ë©˜í…Œì´ì…˜
        print("  ğŸ”¬ Cellpose ì„¸ê·¸ë©˜í…Œì´ì…˜...")
        cellpose_result = self.cellpose.process_image(image_path, visualize=False)
        
        # ì „ì²˜ë¦¬
        input_tensor = self.preprocess_image(image)
        input_tensor = input_tensor.to(self.device)
        
        # ë”¥ëŸ¬ë‹ ì¶”ë¡ 
        print("  ğŸ¤– AI ì¶”ë¡ ...")
        with torch.no_grad():
            logits = self.model(input_tensor)
            probabilities = F.softmax(logits, dim=1)
            confidence, predicted = torch.max(probabilities, dim=1)
        
        predicted_class = predicted.item()
        predicted_name = self.class_names[predicted_class]
        confidence_score = confidence.item()
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            'image_path': str(image_path),
            'timestamp': datetime.now().isoformat(),
            
            # Cellpose ê²°ê³¼
            'cellpose': {
                'num_cells': cellpose_result['num_cells'],
                'feature_vector': cellpose_result['feature_vector'].tolist(),
                'cell_features': cellpose_result['cell_features']
            },
            
            # AI ì˜ˆì¸¡
            'prediction': {
                'class_id': predicted_class,
                'class_name': predicted_name,
                'confidence': confidence_score,
                'probabilities': {
                    name: prob.item() 
                    for name, prob in zip(self.class_names, probabilities[0])
                }
            }
        }
        
        # Grad-CAM ì„¤ëª…
        if explain:
            print("  ğŸ’¡ ì„¤ëª… ìƒì„± (Grad-CAM)...")
            input_tensor.requires_grad = True
            heatmap = self.xai.generate_heatmap(input_tensor, target_class=predicted_class)
            
            # ì˜¤ë²„ë ˆì´ ìƒì„±
            overlay = self.xai.overlay_heatmap(image, heatmap, alpha=0.4)
            
            result['explanation'] = {
                'heatmap': heatmap.tolist(),
                'overlay': overlay
            }
        
        return result
    
    def batch_predict(self, image_paths: List[str], explain: bool = False) -> List[Dict]:
        """ë°°ì¹˜ ì¶”ë¡ """
        results = []
        
        print(f"\nğŸ”„ {len(image_paths)}ê°œ ì´ë¯¸ì§€ ë°°ì¹˜ ì¶”ë¡  ì‹œì‘...\n")
        
        for i, img_path in enumerate(image_paths, 1):
            print(f"[{i}/{len(image_paths)}] {Path(img_path).name}")
            
            try:
                result = self.predict(img_path, explain=explain)
                results.append(result)
                
                print(f"  âœ“ ì˜ˆì¸¡: {result['prediction']['class_name']} "
                      f"(ì‹ ë¢°ë„: {result['prediction']['confidence']:.3f})")
                
            except Exception as e:
                print(f"  âœ— ì˜¤ë¥˜: {e}")
                results.append({
                    'image_path': str(img_path),
                    'error': str(e)
                })
        
        return results
    
    def save_results(self, results: List[Dict], output_path: str):
        """ê²°ê³¼ ì €ì¥"""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì œì™¸ (JSON ì§ë ¬í™” ë¶ˆê°€)
        results_json = []
        for r in results:
            r_copy = r.copy()
            if 'explanation' in r_copy and 'overlay' in r_copy['explanation']:
                del r_copy['explanation']['overlay']
            results_json.append(r_copy)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_json, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ğŸš€ MT-EXO AI Inference Engine í…ŒìŠ¤íŠ¸")
    print("="*80 + "\n")
    
    # ì—”ì§„ ì´ˆê¸°í™”
    engine = MTEXOInferenceEngine(use_gpu=True)
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°
    test_dir = Path(r"c:\Users\brook\Desktop\mi_exo_ai\data\HUVEC TNF-a\HUVEC TNF-a\251209")
    
    if test_dir.exists():
        test_images = list(test_dir.glob("*.jpg"))[:3]
        
        if test_images:
            # ë°°ì¹˜ ì¶”ë¡ 
            results = engine.batch_predict([str(p) for p in test_images], explain=False)
            
            # ê²°ê³¼ ìš”ì•½
            print("\n" + "="*80)
            print("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
            print("="*80 + "\n")
            
            for r in results:
                if 'prediction' in r:
                    print(f"ì´ë¯¸ì§€: {Path(r['image_path']).name}")
                    print(f"  ì˜ˆì¸¡: {r['prediction']['class_name']}")
                    print(f"  ì‹ ë¢°ë„: {r['prediction']['confidence']:.3f}")
                    print(f"  ì„¸í¬ ìˆ˜: {r['cellpose']['num_cells']}")
                    print()
            
            # ì €ì¥
            output_path = "data/AI_Inference_Results/inference_results.json"
            engine.save_results(results, output_path)
            
        else:
            print("âš ï¸  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì—†ìŒ")
    else:
        print(f"âš ï¸  í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {test_dir}")
    
    print("\n" + "="*80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
